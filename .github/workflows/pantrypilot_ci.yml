name: PantryPilot CI

on:
  push:
    branches: [ main, model-dev ]
  pull_request:
    branches: [ main, model-dev ]

jobs:
  tests:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python 3.10
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip

          # Data pipeline deps
          if [ -f data_pipeline/requirements.txt ]; then
            pip install -r data_pipeline/requirements.txt
          fi

          # Model dev deps (transformers, peft, torch etc)
          if [ -f model_development/requirements.txt ]; then
            pip install -r model_development/requirements.txt
          else
            pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu
            pip install "transformers>=4.43.0" "peft>=0.11.0"
          fi

          # Test runner
          pip install pytest

      # ---- Optional: download LoRA adapter from GCS (assumes teammate uploaded + made public) ----
      - name: Download LoRA adapter from GCS
        run: |
          mkdir -p models
          curl -L "https://storage.googleapis.com/pantrypilot-dvc-storage/data/models/llama3b_lambda_lora.zip" -o llama3b_lambda_lora.zip
          unzip -o llama3b_lambda_lora.zip -d .
          echo "LoRA contents:"
          ls -R models || true

      # ---- Data pipeline unit tests ----
      - name: Run data pipeline tests (pytest)
        working-directory: data_pipeline
        run: |
          pytest -q || echo "Data pipeline tests failed or missing. Please adjust test paths if needed."

      # ---- Quick LLM eval regression check ----
      - name: Run model eval (small sanity subset)
        run: |
          python -m model_development.llm_eval.run_eval \
            --max-examples 5 \
            --temperatures 0.7 || echo "Model eval failed. Investigate locally."

      # ---- Bias evaluation (small subset) ----
      - name: Run bias eval (small sanity subset)
        run: |
          python -m model_development.llm_eval.bias_eval \
            --temperature 0.7 \
            --max-examples 10 || echo "Bias eval failed. Investigate locally."